"""
Datasets adapted from Microsoft's csuite library: https://github.com/microsoft/csuite
Distributions adapted from the NumPyro library: https://num.pyro.ai/en/stable/distributions.html
"""

import os

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import torch
from causalgen import Generator

from utils.math_utils import *
from utils.params import SEED


def sanity_check(csuite_dataset, samples=None, original_data_base_path="data/csuite/original_data"):
    """
    Compare the plots of the relative distributions between datasets generated by the methods in the current file and
    the ones given in Microsoft's csuite repository: https://github.com/microsoft/csuite

    :param csuite_dataset: function - one of the csuite datasets defined in this file
    :param samples: int - default None - the number of samples to be generated in the dataset; if None, the number of
        samples set on the number of samples in the original corresponding dataset
    :param original_data_base_path: str - path to the location of the original datasets in csv format
    :return: None
    """

    original_df = pd.read_csv(os.path.join(original_data_base_path, csuite_dataset.__name__ + ".csv"))
    if samples is None:
        samples = len(original_df)

    generated_df = csuite_dataset(samples)
    original_df.columns = generated_df.columns

    sns.set_style("ticks", {"axes.grid": True})

    pl = sns.pairplot(original_df, plot_kws=dict(alpha=0.05, size=0.7), grid_kws={})
    pl.fig.suptitle("Original Data")
    pl.fig.tight_layout()
    plt.show()

    pl = sns.pairplot(generated_df, plot_kws=dict(alpha=0.05, size=0.7), grid_kws={})
    pl.fig.suptitle("Generated Data")
    pl.fig.tight_layout()
    plt.show()

    return None


# Possible adjacency graph formats: list (matrix as list of lists), numpy (2d numpy array), torch (torch tensor)
def lingauss(no_of_samples, generate_data=True, return_adjacency_graph=False, adjacency_graph_format="torch"):
    dg = Generator(seed=SEED)

    dg.normal(mu=0, sigma=1, hidden=False, name="x_0")
    dg.normal(mu=0, sigma=1, hidden=True,  name="z_1")

    dg.descendant(lambda x_0, z_1: 0.5 * x_0 + (np.sqrt(3) / 2) * z_1, hidden=False, name="x_1")

    to_return = tuple()
    if generate_data:
        if no_of_samples < 2:
            no_of_samples = 1
        to_return += (dg.generate(num=no_of_samples, hidden=False),)
    if return_adjacency_graph:
        adjacency_graph = [
            [0, 1],
            [0, 0]
        ]

        if adjacency_graph_format == "list":
            to_return += (adjacency_graph,)
        else:
            adjacency_graph = np.array(adjacency_graph)
            if adjacency_graph_format == "numpy":
                to_return += (adjacency_graph,)
            else:
                to_return += (torch.tensor(adjacency_graph),)

    return to_return


def linexp(no_of_samples, generate_data=True, return_adjacency_graph=False, adjacency_graph_format="torch"):
    dg = Generator(seed=SEED)

    dg.exponential(scale=1, hidden=True, name="z_0")
    dg.exponential(scale=1, hidden=True, name="z_1")

    dg.descendant(lambda z_0: z_0 - 1, hidden=False, name="x_0")
    dg.descendant(lambda x_0, z_1: 0.5 * x_0 + (np.sqrt(3) / 2) * (z_1 - 1), hidden=False, name="x_1")

    to_return = tuple()
    if generate_data:
        if no_of_samples < 2:
            no_of_samples = 1
        to_return += (dg.generate(num=no_of_samples, hidden=False),)
    if return_adjacency_graph:
        adjacency_graph = [
            [0, 1],
            [0, 0]
        ]

        if adjacency_graph_format == "list":
            to_return += (adjacency_graph,)
        else:
            adjacency_graph = np.array(adjacency_graph)
            if adjacency_graph_format == "numpy":
                to_return += (adjacency_graph,)
            else:
                to_return += (torch.tensor(adjacency_graph),)

    return to_return


def nonlingauss(no_of_samples, generate_data=True, return_adjacency_graph=False, adjacency_graph_format="torch"):
    alpha = np.sqrt(1 - 6 * ((1 / np.sqrt(5)) - (1 / 3)))

    dg = Generator(seed=SEED)

    dg.normal(mu=0, sigma=1, hidden=False, name="x_0")
    dg.normal(mu=0, sigma=1, hidden=True,  name="z_1")

    dg.descendant(lambda x_0, z_1: (np.sqrt(6) * np.exp(-(x_0 ** 2))) + alpha * z_1, hidden=False, name="x_1")

    to_return = tuple()
    if generate_data:
        if no_of_samples < 2:
            no_of_samples = 1
        to_return += (dg.generate(num=no_of_samples, hidden=False),)
    if return_adjacency_graph:
        adjacency_graph = [
            [0, 1],
            [0, 0]
        ]

        if adjacency_graph_format == "list":
            to_return += (adjacency_graph,)
        else:
            adjacency_graph = np.array(adjacency_graph)
            if adjacency_graph_format == "numpy":
                to_return += (adjacency_graph,)
            else:
                to_return += (torch.tensor(adjacency_graph),)

    return to_return


# noinspection PyTypeChecker
def nonlin_simpson(no_of_samples, generate_data=True, return_adjacency_graph=False, adjacency_graph_format="torch"):
    dg = Generator(seed=SEED)

    dg.normal(mu=0, sigma=1, hidden=False, name="x_0")
    dg.normal(mu=0, sigma=1, hidden=True,  name="z_2")

    dg.descendant(
        function=lambda x_0: dg.random.normal(loc=softplus(1 - x_0) - 1.5, scale=0.15),
        hidden=False,
        name="x_1"
    )
    dg.descendant(lambda x_1, x_0, z_2: np.tanh(2 * x_1) + 1.5 * x_0 - 1 + np.tanh(z_2), hidden=False, name="x_2")
    dg.descendant(
        function=lambda x_2: dg.random.laplace(loc=5 * np.tanh((x_2 - 4) / 5) + 3, scale=0.1),
        hidden=False,
        name="x_3"
    )

    to_return = tuple()
    if generate_data:
        if no_of_samples < 2:
            no_of_samples = 1
        to_return += (dg.generate(num=no_of_samples, hidden=False),)
    if return_adjacency_graph:
        adjacency_graph = [
            [0, 1, 1, 0],
            [0, 0, 1, 0],
            [0, 0, 0, 1],
            [0, 0, 0, 0]
        ]

        if adjacency_graph_format == "list":
            to_return += (adjacency_graph,)
        else:
            adjacency_graph = np.array(adjacency_graph)
            if adjacency_graph_format == "numpy":
                to_return += (adjacency_graph,)
            else:
                to_return += (torch.tensor(adjacency_graph),)

    return to_return


# noinspection PyTypeChecker
def symprod_simpson(no_of_samples, generate_data=True, return_adjacency_graph=False, adjacency_graph_format="torch"):
    dg = Generator(seed=SEED)

    dg.normal(mu=0, sigma=1, hidden=False, name="x_0")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_1_0")
    dg.custom(lambda size: dg.random.chisquare(df=3.0, size=size), hidden=True, name="z_1_1")

    dg.descendant(
        function=lambda x_0, z_1_0, z_1_1: 2 * np.tanh(x_0 * 2) + 0.1 * z_1_0 * np.sqrt(3.0 / z_1_1),
        hidden=False,
        name="x_1"
    )

    dg.descendant(
        function=lambda x_0, x_1: dg.random.laplace(loc=0.5 * x_0 * x_1, scale=0.5),
        hidden=False,
        name="x_2"
    )

    dg.descendant(
        function=lambda x_0: dg.random.normal(loc=np.tanh(1.5 * x_0), scale=0.3),
        hidden=False,
        name="x_3"
    )

    to_return = tuple()
    if generate_data:
        if no_of_samples < 2:
            no_of_samples = 1
        to_return += (dg.generate(num=no_of_samples, hidden=False),)
    if return_adjacency_graph:
        adjacency_graph = [
            [0, 1, 1, 1],
            [0, 0, 1, 0],
            [0, 0, 0, 0],
            [0, 0, 0, 0]
        ]

        if adjacency_graph_format == "list":
            to_return += (adjacency_graph,)
        else:
            adjacency_graph = np.array(adjacency_graph)
            if adjacency_graph_format == "numpy":
                to_return += (adjacency_graph,)
            else:
                to_return += (torch.tensor(adjacency_graph),)

    return to_return


# noinspection PyTypeChecker
def large_backdoor(no_of_samples, generate_data=True, return_adjacency_graph=False, adjacency_graph_format="torch"):
    dg = Generator(seed=SEED)

    dg.normal(mu=0, sigma=1, hidden=True, name="z_0")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_2")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_3")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_4")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_5")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_6")

    dg.descendant(lambda z_0: softplus(1.8 * z_0) - 1, hidden=False, name="x_0")
    dg.descendant(
        function=lambda x_0: dg.random.normal(loc=soft_truncation(x_0, 0) * 1.5, scale=0.25),
        hidden=False,
        name="x_1")
    dg.descendant(lambda x_0, z_2: soft_truncation(x_0, z_2), hidden=False, name="x_2")
    dg.descendant(lambda x_1, z_3: soft_truncation(x_1, z_3), hidden=False, name="x_3")
    dg.descendant(lambda x_2, z_4: soft_truncation(x_2, z_4), hidden=False, name="x_4")
    dg.descendant(lambda x_3, z_5: soft_truncation(x_3, z_5), hidden=False, name="x_5")
    dg.descendant(lambda x_4, z_6: soft_truncation(x_4, z_6), hidden=False, name="x_6")
    dg.descendant(
        function=lambda x_5: dg.random.normal(loc=softplus(x_5 + 1) * 1.5 - 1, scale=0.3),
        hidden=False,
        name="x_7"
    )
    dg.descendant(
        function=lambda x_6, x_7: dg.random.laplace(loc=-softplus((-x_6 * 1.3 + x_7) / 3 + 1) + 2, scale=0.6),
        hidden=False,
        name="x_8"
    )

    to_return = tuple()
    if generate_data:
        if no_of_samples < 2:
            no_of_samples = 1
        to_return += (dg.generate(num=no_of_samples, hidden=False),)
    if return_adjacency_graph:
        adjacency_graph = [
            [0, 1, 1, 0, 0, 0, 0, 0, 0],  # x0
            [0, 0, 0, 1, 0, 0, 0, 0, 0],  # x1
            [0, 0, 0, 0, 1, 0, 0, 0, 0],  # x2
            [0, 0, 0, 0, 0, 1, 0, 0, 0],  # x3
            [0, 0, 0, 0, 0, 0, 1, 0, 0],  # x4
            [0, 0, 0, 0, 0, 0, 0, 1, 0],  # x5
            [0, 0, 0, 0, 0, 0, 0, 0, 1],  # x6
            [0, 0, 0, 0, 0, 0, 0, 0, 1],  # x7
            [0, 0, 0, 0, 0, 0, 0, 0, 0]   # x8
        ]

        if adjacency_graph_format == "list":
            to_return += (adjacency_graph,)
        else:
            adjacency_graph = np.array(adjacency_graph)
            if adjacency_graph_format == "numpy":
                to_return += (adjacency_graph,)
            else:
                to_return += (torch.tensor(adjacency_graph),)

    return to_return


# noinspection PyTypeChecker
def weak_arrows(no_of_samples, generate_data=True, return_adjacency_graph=False, adjacency_graph_format="torch"):
    dg = Generator(seed=SEED)

    dg.normal(mu=0, sigma=1, hidden=True, name="z_0")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_2")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_3")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_4")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_5")
    dg.normal(mu=0, sigma=1, hidden=True, name="z_6")

    dg.descendant(lambda z_0: softplus(1.8 * z_0) - 1, hidden=False, name="x_0")
    dg.descendant(
        function=lambda x_0: dg.random.normal(loc=soft_truncation(x_0, 0) * 0.75, scale=0.75),
        hidden=False,
        name="x_1"
    )
    dg.descendant(lambda x_0, z_2: reverse_soft_truncation(x_0, z_2), hidden=False, name="x_2")
    dg.descendant(lambda x_1, z_3: reverse_soft_truncation(x_1, z_3), hidden=False, name="x_3")
    dg.descendant(lambda x_2, z_4: soft_truncation(x_2, z_4), hidden=False, name="x_4")
    dg.descendant(lambda x_3, z_5: soft_truncation(x_3, z_5), hidden=False, name="x_5")
    dg.descendant(lambda x_4, z_6: soft_truncation(x_4, z_6), hidden=False, name="x_6")
    dg.descendant(
        function=lambda x_5: dg.random.normal(loc=softplus(x_5 + 1) * 1.5 - 1, scale=0.3),
        hidden=False,
        name="x_7"
    )
    dg.descendant(
        function=lambda x_0, x_1, x_2, x_3, x_4, x_5, x_6, x_7: dg.random.laplace(
            loc=softplus(
                0.1 * x_0 + 0.1 * x_1 + 0.1 * x_2 + 0.1 * x_3 + 0.1 * x_4 + 0.1 * x_5 + 0.5 * x_6 + 0.7 * x_7 + 1
            ),
            scale=0.5
        ),
        hidden=False,
        name="x_8"
    )

    to_return = tuple()
    if generate_data:
        if no_of_samples < 2:
            no_of_samples = 1
        to_return += (dg.generate(num=no_of_samples, hidden=False),)
    if return_adjacency_graph:
        adjacency_graph = [
            [0, 1, 1, 0, 0, 0, 0, 0, 1],  # x0
            [0, 0, 0, 1, 0, 0, 0, 0, 1],  # x1
            [0, 0, 0, 0, 1, 0, 0, 0, 1],  # x2
            [0, 0, 0, 0, 0, 1, 0, 0, 1],  # x3
            [0, 0, 0, 0, 0, 0, 1, 0, 1],  # x4
            [0, 0, 0, 0, 0, 0, 0, 1, 1],  # x5
            [0, 0, 0, 0, 0, 0, 0, 0, 1],  # x6
            [0, 0, 0, 0, 0, 0, 0, 0, 1],  # x7
            [0, 0, 0, 0, 0, 0, 0, 0, 0]   # x8
        ]

        if adjacency_graph_format == "list":
            to_return += (adjacency_graph,)
        else:
            adjacency_graph = np.array(adjacency_graph)
            if adjacency_graph_format == "numpy":
                to_return += (adjacency_graph,)
            else:
                to_return += (torch.tensor(adjacency_graph),)

    return to_return
